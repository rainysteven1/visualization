FROM base:0.1.0
LABEL authoer="rainy"
LABEL email="rainysteven1@gmail.com"


COPY config /tmp

#添加JDK
ADD ./software/jdk-8u341-linux-aarch64.tar.gz /usr/local/
#添加hadoop
ADD ./software/hadoop-3.2.0.tar.gz  /usr/local
#添加scala
ADD ./software/scala-2.12.16.tgz /usr/local
#添加spark
ADD ./software/spark-3.1.3-bin-hadoop3.2.tgz /usr/local
#添加hive
ADD ./software/apache-hive-3.1.2-bin.tar.gz /usr/local


RUN echo "export JAVA_HOME=/usr/local/jdk1.8.0_341" | cat >> /usr/local/hadoop-3.2.0/etc/hadoop/yarn-env.sh
#添加mysql-connector-java-8.0.29.jar到hive的lib目录中
ADD ./software/mysql-connector-java-8.0.29.jar /usr/local/apache-hive-3.1.2-bin/lib
RUN cp /usr/local/apache-hive-3.1.2-bin/lib/mysql-connector-java-8.0.29.jar /usr/local/spark-3.1.3-bin-hadoop3.2/jars


#增加JAVA_HOME环境变量
ENV JAVA_HOME /usr/local/jdk1.8.0_341
#hadoop环境变量
ENV HADOOP_HOME /usr/local/hadoop-3.2.0 
#scala环境变量
ENV SCALA_HOME /usr/local/scala-2.12.16
#spark环境变量
ENV SPARK_HOME /usr/local/spark-3.1.3-bin-hadoop3.2
#hive环境变量
ENV HIVE_HOME /usr/local/apache-hive-3.1.2-bin
ENV PATH $HIVE_HOME/bin:$SCALA_HOME/bin:$SPARK_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$PATH

#将配置移动到正确的位置
RUN mv /tmp/file/profile /etc/profile &&\
    mv /tmp/spark/workers $SPARK_HOME/conf/workers && \
    mv /tmp/spark/spark-defaults.conf $SPARK_HOME/conf/spark-defaults.conf && \
    mv /tmp/spark/spark-env.sh $SPARK_HOME/conf/spark-env.sh && \
    cp /tmp/hive/hive-site.xml $SPARK_HOME/conf/hive-site.xml && \
    cp /tmp/hadoop/hdfs-site.xml $SPARK_HOME/conf/hdfs-site.xml && \
    cp /tmp/hadoop/core-site.xml $SPARK_HOME/conf/hdfs-site.xml && \
    mv /tmp/hive/hive-site.xml $HIVE_HOME/conf/hive-site.xml && \
    mv /tmp/hive/hive-env.sh $HIVE_HOME/conf/hive-env.sh && \
    mv /tmp/hadoop/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml && \
    mv /tmp/hadoop/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml && \
    mv /tmp/hadoop/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml && \
    mv /tmp/hadoop/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml && \
    mv /tmp/hadoop/hadoop-env.sh $HADOOP_HOME/etc/hadoop/hadoop-env.sh && \
    mv /tmp/hadoop/workers $HADOOP_HOME/etc/hadoop/workers && \
    mv /tmp/scripts/start-hadoop.sh ~/start-hadoop.sh && \
    mv /tmp/scripts/init_hive.sh ~/init_hive.sh && chmod 700 ~/init_hive.sh && \
    mv /tmp/scripts/restart-hadoop.sh ~/restart-hadoop.sh && chmod 700 ~/restart-hadoop.sh

RUN cp $HIVE_HOME/lib/guava-19.0.jar $HADOOP_HOME/share/hadoop/common/lib && \
    rm -rf $HADOOP_HOME/share/hadoop/common/lib/guava-11.0.2.jar

RUN ssh-keygen -t rsa -C rainysteven1@gmail.com -f ~/.ssh/id_rsa -P '' && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
    chmod 600 ~/.ssh/authorized_keys

RUN echo $JAVA_HOME
#设置工作目录
WORKDIR /root
EXPOSE 22
#启动sshd服务
RUN set -x && \
    sed -i "s/#PermitRootLogin prohibit-password/PermitRootLogin yes/g" /etc/ssh/sshd_config && \
    sed -i "s/#PasswordAuthentication yes/PasswordAuthentication yes/g" /etc/ssh/sshd_config
RUN /etc/init.d/ssh start 

RUN echo root:wang120638 | chpasswd

#修改root密码
CMD ["/bin/bash"]